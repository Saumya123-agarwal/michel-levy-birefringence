{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: DL Birefringence Prediction from POM Images\n",
    "\n",
    "**One-click training pipeline for Google Colab (Free GPU)**\n",
    "\n",
    "This notebook trains a hybrid CNN model to predict birefringence (Δn) from:\n",
    "- POM microscopy images\n",
    "- Temperature, thickness, and order\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Mount Google Drive (upload your project folder there)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set your project path (update this to match your Drive folder)\n",
    "PROJECT_ROOT = '/content/drive/MyDrive/phase2_birefringence'\n",
    "\n",
    "# Or clone from GitHub:\n",
    "# !git clone https://github.com/YOUR_USERNAME/phase2_birefringence.git\n",
    "# PROJECT_ROOT = '/content/phase2_birefringence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Install dependencies\n",
    "!pip install -q torch torchvision timm xgboost scikit-learn openpyxl pillow pandas numpy matplotlib seaborn tqdm\n",
    "\n",
    "# Verify GPU\n",
    "import torch\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(PROJECT_ROOT)\n",
    "import sys\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "# Check project structure\n",
    "!ls -la\n",
    "!ls -la data/ 2>/dev/null || echo 'data/ not found yet'\n",
    "!ls -la src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your dataset zip is in the project folder:\n",
    "!unzip -o dataset_physics_SOP_liquid_crystal.zip -d dataset/ 2>/dev/null || echo 'Dataset already extracted or not found'\n",
    "\n",
    "# Prepare unified CSV\n",
    "!python src/prepare_dataset.py \\\n",
    "    --data-root dataset/dataset_physics_SOP_liquid_crystal \\\n",
    "    --p100-thickness 9.415 \\\n",
    "    --p100-order 1 \\\n",
    "    --pch-thickness 10.0 \\\n",
    "    --pch-order 1 \\\n",
    "    --output data/dataset_unified.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/dataset_unified.csv')\n",
    "print(f'Total samples: {len(df)}')\n",
    "print(df.groupby('material').agg({\n",
    "    'temperature_C': ['min', 'max', 'count'],\n",
    "    'delta_n': ['min', 'max', 'mean'],\n",
    "}))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize delta_n vs temperature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "for i, mat in enumerate(df['material'].unique()):\n",
    "    sub = df[df['material'] == mat].sort_values('temperature_C')\n",
    "    axes[i].plot(sub['temperature_C'], sub['delta_n'], 'o-', markersize=6)\n",
    "    axes[i].set_xlabel('Temperature (°C)')\n",
    "    axes[i].set_ylabel('Δn')\n",
    "    axes[i].set_title(mat)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run Baseline (XGBoost + Color Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/baseline_xgboost.py --csv data/dataset_unified.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train DL Model (Hybrid CNN)\n",
    "\n",
    "This uses EfficientNet-B0 pretrained backbone + scalar fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold Cross-Validation (recommended first)\n",
    "!python src/train.py \\\n",
    "    --csv data/dataset_unified.csv \\\n",
    "    --backbone efficientnet_b0 \\\n",
    "    --epochs 60 \\\n",
    "    --warmup-epochs 10 \\\n",
    "    --batch-size 16 \\\n",
    "    --lr 1e-3 \\\n",
    "    --n-patches 25 \\\n",
    "    --cv-mode kfold \\\n",
    "    --n-folds 5 \\\n",
    "    --save-final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) LOOCV for more rigorous evaluation\n",
    "# This takes longer but uses every image for validation once\n",
    "# !python src/train.py \\\n",
    "#     --csv data/dataset_unified.csv \\\n",
    "#     --backbone efficientnet_b0 \\\n",
    "#     --epochs 60 \\\n",
    "#     --cv-mode loocv \\\n",
    "#     --save-final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Find latest results file\n",
    "dl_results = sorted(glob.glob('results/cv_results_*.json'))[-1]\n",
    "print(f'Latest DL results: {dl_results}')\n",
    "\n",
    "!python src/visualize.py --results {dl_results} --type dl\n",
    "\n",
    "# Display plots\n",
    "from IPython.display import Image as IPImage, display\n",
    "for plot in sorted(glob.glob('results/plots/*.png')):\n",
    "    print(f'\\n{plot}:')\n",
    "    display(IPImage(plot, width=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline vs DL\n",
    "baseline_results = sorted(glob.glob('results/baseline_results_*.json'))[-1]\n",
    "\n",
    "import json\n",
    "with open(baseline_results) as f:\n",
    "    bl = json.load(f)\n",
    "with open(dl_results) as f:\n",
    "    dl = json.load(f)\n",
    "\n",
    "print('='*50)\n",
    "print('MODEL COMPARISON')\n",
    "print('='*50)\n",
    "print(f'{\"Metric\":<12} {\"XGBoost\":>12} {\"CNN\":>12}')\n",
    "print('-'*36)\n",
    "print(f'{\"MAE\":<12} {bl[\"mae\"]:>12.6f} {dl[\"overall_mae\"]:>12.6f}')\n",
    "print(f'{\"RMSE\":<12} {bl[\"rmse\"]:>12.6f} {dl[\"overall_rmse\"]:>12.6f}')\n",
    "print(f'{\"R²\":<12} {bl[\"r2\"]:>12.4f} {dl[\"overall_r2\"]:>12.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Predict on New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict birefringence for a new POM image\n",
    "!python src/predict.py \\\n",
    "    --image 'dataset/dataset_physics_SOP_liquid_crystal/P100-7CB+ Str +t3318/35.jpg' \\\n",
    "    --temperature 35.0 \\\n",
    "    --thickness 9.415 \\\n",
    "    --order 1 \\\n",
    "    --model models/birefringence_model_efficientnet_b0.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch predict for all images (sanity check)\n",
    "from src.predict import load_model, predict_birefringence\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = load_model('models/birefringence_model_efficientnet_b0.pth', device)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    mean_dn, std_dn, _, _ = predict_birefringence(\n",
    "        model, row['image_path'], row['temperature_C'],\n",
    "        row['thickness_um'], row['order'], device, n_patches=10,\n",
    "    )\n",
    "    err = abs(mean_dn - row['delta_n'])\n",
    "    print(f\"T={row['temperature_C']:5.1f}°C | True={row['delta_n']:.5f} | \"\n",
    "          f\"Pred={mean_dn:.5f} ± {std_dn:.5f} | Err={err:.5f} | {row['material']}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
